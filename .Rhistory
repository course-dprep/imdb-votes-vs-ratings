library(readr)
# Programmatic download (sample size for speed/reproducibility)
basics <- read_tsv(
"https://datasets.imdbws.com/title.basics.tsv.gz",
na = "\\N",
col_select = c(tconst, titleType, startYear, genres),
n_max = 200000
)
ratings <- read_tsv(
"https://datasets.imdbws.com/title.ratings.tsv.gz",
na = "\\N",
col_select = c(tconst, averageRating, numVotes),
n_max = 200000
)
library(dplyr)
library(tidyr)
library(tidyr)
library(ggplot2)
# List all packages here using library()
library(readr)
library(tidyverse)
library(dplyr)
library(tidyr)
library(ggplot2)
library(here)
library(vroom)
source("src/1-raw-data/loading-packages.R")
# Define data directory for reproducibility
data_dir <- here("src", "data")
basics_path  <- file.path(data_dir, "title.basics.tsv.gz")
ratings_path <- file.path(data_dir, "title.ratings.tsv.gz")
# Define sources (IMDb datasets)
basics_url  <- "https://datasets.imdbws.com/title.basics.tsv.gz"
ratings_url <- "https://datasets.imdbws.com/title.ratings.tsv.gz"
# Download datasets
download.file(basics_url, basics_path, mode = "wb", quiet = TRUE)
download.file(ratings_url, ratings_path, mode = "wb", quiet = TRUE)
# Transformation
# Random sample with reproducibility
set.seed(123)
sample_basics <- vroom(basics_path, delim = "\t") %>%
slice_sample(n = 200000)
set.seed(123)
sample_ratings <- vroom(ratings_path, delim = "\t") %>%
slice_sample(n = 200000)
# Output
message("Random samples created:")
message("Sample basics rows: ", nrow(sample_basics))
message("Sample ratings rows: ", nrow(sample_ratings))
getwd()
# In this directory, you will keep all source code files relevant for
# preparing/cleaning your data.
source("src/1-raw-data/loading-packages.R")
# read sample files
basics_path  <- "src/data/title.basics.tsv.gz"
ratings_path <- "src/data/title.ratings.tsv.gz"
basics  <- read_tsv(basics_path,  na = "\\N",
col_select = c(tconst, titleType, startYear, genres),
show_col_types = FALSE)
ratings <- read_tsv(ratings_path, na = "\\N",
col_select = c(tconst, averageRating, numVotes),
show_col_types = FALSE)
# TRANSFORMATION
# Merge on tconst
imdb_raw <- basics %>%
inner_join(ratings, by = "tconst")
# type casting and selection of relevant title types
imdb_raw <- imdb_raw %>%
mutate(
startYear = suppressWarnings(as.integer(startYear)),
type = if_else(titleType %in% c("movie", "tvMovie"), "movie",
if_else(titleType %in% c("tvSeries", "tvMiniSeries"), "series", "other"))
) %>%
filter(type %in% c("movie", "series"))
# remove duplicates
imdb_dedup <- imdb_raw %>%
distinct(tconst, .keep_all = TRUE)
# filter out the noise
imdb_clean <- imdb_dedup %>%
filter(numVotes >= 1000)
# Feature engineering: genre_family
genre_map <- imdb_clean %>%
filter(!is.na(genres), genres != "") %>%
select(tconst, genres) %>%
separate_rows(genres, sep = ",") %>%
mutate(fam = case_when(
genres %in% c("Fantasy","Comedy","Romance","Action","Adventure","Animation","Family") ~ "Escapist",
genres %in% c("Drama","Thriller","Biography","Crime","Documentary") ~ "Heavy",
TRUE ~ NA_character_
)) %>%
group_by(tconst) %>%
summarise(
genre_family = case_when(
all(is.na(fam))               ~ NA_character_,
n_distinct(na.omit(fam)) == 1 ~ first(na.omit(fam)),
n_distinct(na.omit(fam)) >  1 ~ "Gemixt"
),
.groups = "drop"
)
# merge with extra features
imdb_enriched <- imdb_clean %>%
left_join(genre_map, by = "tconst") %>%
select(tconst, titleType, type, startYear, genres, genre_family,
averageRating, numVotes)
# OUTPUT
dir.create("data/clean", showWarnings = FALSE, recursive = TRUE)
write_csv(imdb_clean,    "data/clean/imdb_clean.csv")
write_rds(imdb_clean,    "data/clean/imdb_clean.rds")
write_csv(imdb_enriched, "data/clean/imdb_enriched.csv")
write_rds(imdb_enriched, "data/clean/imdb_enriched.rds")
# List all packages here using library()
library(readr)
library(tidyverse)
library(dplyr)
library(tidyr)
library(ggplot2)
library(here)
library(vroom)
# Define data directory for reproducibility
data_dir <- here("src", "data")
basics_path  <- file.path(data_dir, "title.basics.tsv.gz")
ratings_path <- file.path(data_dir, "title.ratings.tsv.gz")
# Define sources (IMDb datasets)
basics_url  <- "https://datasets.imdbws.com/title.basics.tsv.gz"
ratings_url <- "https://datasets.imdbws.com/title.ratings.tsv.gz"
# Download datasets
download.file(basics_url, basics_path, mode = "wb", quiet = TRUE)
download.file(ratings_url, ratings_path, mode = "wb", quiet = TRUE)
# Transformation
# Random sample with reproducibility
set.seed(123)
sample_basics <- vroom(basics_path, delim = "\t") %>%
slice_sample(n = 200000)
set.seed(123)
sample_ratings <- vroom(ratings_path, delim = "\t") %>%
slice_sample(n = 200000)
# Output
message("Random samples created:")
message("Sample basics rows: ", nrow(sample_basics))
message("Sample ratings rows: ", nrow(sample_ratings))
# In this directory, you will keep all source code files relevant for
# preparing/cleaning your data.
source("src/1-raw-data/loading-packages.R")
# read sample files
basics_path  <- "src/data/title.basics.tsv.gz"
ratings_path <- "src/data/title.ratings.tsv.gz"
basics  <- read_tsv(basics_path,  na = "\\N",
col_select = c(tconst, titleType, startYear, genres),
show_col_types = FALSE)
ratings <- read_tsv(ratings_path, na = "\\N",
col_select = c(tconst, averageRating, numVotes),
show_col_types = FALSE)
# TRANSFORMATION
# Merge on tconst
imdb_raw <- basics %>%
inner_join(ratings, by = "tconst")
# type casting and selection of relevant title types
imdb_raw <- imdb_raw %>%
mutate(
startYear = suppressWarnings(as.integer(startYear)),
type = if_else(titleType %in% c("movie", "tvMovie"), "movie",
if_else(titleType %in% c("tvSeries", "tvMiniSeries"), "series", "other"))
) %>%
filter(type %in% c("movie", "series"))
# remove duplicates
imdb_dedup <- imdb_raw %>%
distinct(tconst, .keep_all = TRUE)
# filter out the noise
imdb_clean <- imdb_dedup %>%
filter(numVotes >= 1000)
# Feature engineering: genre_family
genre_map <- imdb_clean %>%
filter(!is.na(genres), genres != "") %>%
select(tconst, genres) %>%
separate_rows(genres, sep = ",") %>%
mutate(fam = case_when(
genres %in% c("Fantasy","Comedy","Romance","Action","Adventure","Animation","Family") ~ "Escapist",
genres %in% c("Drama","Thriller","Biography","Crime","Documentary") ~ "Heavy",
TRUE ~ NA_character_
)) %>%
group_by(tconst) %>%
summarise(
genre_family = case_when(
all(is.na(fam))               ~ NA_character_,
n_distinct(na.omit(fam)) == 1 ~ first(na.omit(fam)),
n_distinct(na.omit(fam)) >  1 ~ "Gemixt"
),
.groups = "drop"
)
# merge with extra features
imdb_enriched <- imdb_clean %>%
left_join(genre_map, by = "tconst") %>%
select(tconst, titleType, type, startYear, genres, genre_family,
averageRating, numVotes)
# OUTPUT
dir.create("data/clean", showWarnings = FALSE, recursive = TRUE)
write_csv(imdb_clean,    "data/clean/imdb_clean.csv")
write_rds(imdb_clean,    "data/clean/imdb_clean.rds")
write_csv(imdb_enriched, "data/clean/imdb_enriched.csv")
write_rds(imdb_enriched, "data/clean/imdb_enriched.rds")
# In this directory, you will keep all source code related to your analysis.
# Exploration of main question
ggplot(imdb_all, aes(x=log10(numVotes), y=averageRating)) +
geom_point(alpha=.2) +
geom_smooth(method="lm") +
labs(title="Votes vs Average Rating (All Titles)",
x="log10(Number of Votes)", y="Average Rating")
View(genre_map)
View(imdb_clean)
View(imdb_dedup)
setwd("~/Documents/Master_Y1_B1/course-dataprep/Team_project/imdb-votes-vs-ratings/src/1-raw-data")
setwd()
setwd("~/Documents/Master_Y1_B1/course-dataprep/Team_project/imdb-votes-vs-ratings")
cd
# List all packages here using library()
library(readr)
library(tidyverse)
library(dplyr)
library(tidyr)
library(ggplot2)
library(here)
library(vroom)
source("src/1-raw-data/loading-packages.R")
# Define data directory for reproducibility
data_dir <- here("src", "data")
basics_path  <- file.path(data_dir, "title.basics.tsv.gz")
ratings_path <- file.path(data_dir, "title.ratings.tsv.gz")
# Define sources (IMDb datasets)
basics_url  <- "https://datasets.imdbws.com/title.basics.tsv.gz"
ratings_url <- "https://datasets.imdbws.com/title.ratings.tsv.gz"
# Download datasets
download.file(basics_url, basics_path, mode = "wb", quiet = TRUE)
download.file(ratings_url, ratings_path, mode = "wb", quiet = TRUE)
# Transformation
# Random sample with reproducibility
set.seed(123)
sample_basics <- vroom(basics_path, delim = "\t") %>%
slice_sample(n = 200000)
set.seed(123)
sample_ratings <- vroom(ratings_path, delim = "\t") %>%
slice_sample(n = 200000)
# Output
message("Random samples created:")
message("Sample basics rows: ", nrow(sample_basics))
message("Sample ratings rows: ", nrow(sample_ratings))
source("src/1-raw-data/loading-packages.R")
# Define data directory for reproducibility
data_dir <- here("src", "data")
basics_path  <- file.path(data_dir, "title.basics.tsv.gz")
ratings_path <- file.path(data_dir, "title.ratings.tsv.gz")
# Define sources (IMDb datasets)
basics_url  <- "https://datasets.imdbws.com/title.basics.tsv.gz"
ratings_url <- "https://datasets.imdbws.com/title.ratings.tsv.gz"
# Download datasets
download.file(basics_url, basics_path, mode = "wb", quiet = TRUE)
# List all packages here using library()
library(readr)
library(tidyverse)
library(dplyr)
library(tidyr)
library(ggplot2)
library(here)
library(vroom)
source("src/1-raw-data/loading-packages.R")
# Define data directory for reproducibility
data_dir <- here("src", "data")
basics_path  <- file.path(data_dir, "title.basics.tsv.gz")
ratings_path <- file.path(data_dir, "title.ratings.tsv.gz")
# Define sources (IMDb datasets)
basics_url  <- "https://datasets.imdbws.com/title.basics.tsv.gz"
ratings_url <- "https://datasets.imdbws.com/title.ratings.tsv.gz"
# Download datasets
download.file(basics_url, basics_path, mode = "wb", quiet = TRUE)
setwd("~/Documents/Master_Y1_B1/course-dataprep/Team_project/imdb-votes-vs-ratings/src/1-raw-data")
source("src/1-raw-data/loading-packages.R")
# List all packages here using library()
library(readr)
library(tidyverse)
library(dplyr)
library(tidyr)
library(ggplot2)
library(here)
library(vroom)
source("src/1-raw-data/loading-packages.R")
